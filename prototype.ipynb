{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG: Plot page element boxes\n",
    "def draw_page_boxes(page_image, table_location=None, row_boxes=None, column_boxes=None):\n",
    "\n",
    "\t# Draw page\n",
    "\tfig, ax = plt.subplots()\n",
    "\tfig.set_size_inches(8.5, 11)\n",
    "\tCOLORS = [[0.000, 0.447, 0.741], [0.850, 0.525, 0.398], [0.629, 0.194, 0.625], [0.494, 0.184, 0.556], [0.466, 0.674, 0.188], [0.301, 0.745, 0.933]]\n",
    "\tnum_colors = len(COLORS)\n",
    "\tax.axis('off')\n",
    "\tax.imshow(page_image)\n",
    "\n",
    "\t# Draw table box\n",
    "\tif table_location:\n",
    "\t\tpadding = 4\n",
    "\t\t(tl_xmin, tl_ymin, tl_xmax, tl_ymax) = table_location\n",
    "\t\tax.add_patch(plt.Rectangle((tl_xmin - padding, tl_ymin - padding), tl_xmax - tl_xmin + padding * 2, tl_ymax - tl_ymin + padding * 2, fill=False, color=[1, 0, 0], linewidth=0.5))\n",
    "\n",
    "\t# Draw row boxes\n",
    "\tif row_boxes:\n",
    "\t\tfor i, box in enumerate(row_boxes):\n",
    "\t\t\t(xmin, ymin, xmax, ymax) = box\n",
    "\t\t\tax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color=COLORS[0], linewidth=0.5))\n",
    "\n",
    "\t# Draw column boxes\n",
    "\tif column_boxes:\n",
    "\t\tfor i, box in enumerate(column_boxes):\n",
    "\t\t\t(xmin, ymin, xmax, ymax) = box\n",
    "\t\t\tax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, color=COLORS[i % len(COLORS)], linewidth=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Processing functions\n",
    "#\n",
    "import base64\n",
    "import cv2\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import re\n",
    "import torch\n",
    "\n",
    "from gtts import gTTS\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from transformers import DetrFeatureExtractor, TableTransformerForObjectDetection\n",
    "\n",
    "#\n",
    "# Check if columns are closely adjacent\n",
    "#\n",
    "def are_columns_adjacent(box1, box2):\n",
    "  return abs(box2[2] - box1[0]) < 2 or abs(box1[2] - box2[0]) < 2\n",
    "\n",
    "#\n",
    "# Calculate the bounding box area\n",
    "#\n",
    "def box_area(box):\n",
    "  return (box[2]-box[0]) * (box[3]-box[1])\n",
    "\n",
    "#\n",
    "# Convert image string to image\n",
    "#\n",
    "def convert_image_string(page_image_string):\n",
    "\n",
    "\t# Strip base64 header\n",
    "\tbase64_image_string = page_image_string.partition(\"base64,\")[-1]\n",
    "\n",
    "\t# Convert base64 string to byte buffer\n",
    "\timage_buffer = base64.b64decode(base64_image_string)\n",
    "\tpage_image = Image.open(io.BytesIO(image_buffer)).convert(\"RGB\")\n",
    "\n",
    "\treturn page_image\n",
    "\n",
    "#\n",
    "# Convert cell text to base64 audio string\n",
    "#\n",
    "def create_audio_string(cell_text):\n",
    "\n",
    "\t# Define base64 audio prefix\n",
    "\tbase64_audio_prefix = \"data:audio/mp3;base64,\"\n",
    "\n",
    "\t# Remember negative numbers\n",
    "\tnegative = False\n",
    "\tnormalized_text = cell_text.strip()\n",
    "\tif normalized_text.startswith(\"(\") and normalized_text.endswith(\")\"):\n",
    "\t\tnegative = True\n",
    "\n",
    "\t# Prep cell text\n",
    "\tnormalized_text = re.sub(r\"[(), ]\", \"\", cell_text) # Remove non-read chars\n",
    "\n",
    "\t# Convert text to audio\n",
    "\tbase64_audio_string = \"\"\n",
    "\tif normalized_text:\n",
    "\n",
    "\t\t# Space out characters\n",
    "\t\tnormalized_text = \" \".join(normalized_text)\n",
    "\n",
    "\t\t# Say special words\n",
    "\t\tnormalized_text = normalized_text.replace(\".\", \"point\")\t# Decimal point\n",
    "\t\tnormalized_text = normalized_text.replace(\"0\", \"zero\")\t# Zero\n",
    "\t\tif negative:\n",
    "\t\t\tnormalized_text = \"minus \" + normalized_text # Negative\n",
    "\n",
    "\t\t# Convert text to speech\n",
    "\t\tcell_audio = gTTS(text=normalized_text, lang=\"en\", slow=False)\n",
    "\n",
    "\t\t# Convert audio to base64\n",
    "\t\taudio_buffer = BytesIO()\n",
    "\t\tcell_audio.write_to_fp(audio_buffer)\n",
    "\t\taudio_buffer.seek(0)\n",
    "\t\tbase64_audio_string = base64_audio_prefix + base64.b64encode(audio_buffer.read()).decode(\"utf-8\")\n",
    "\n",
    "\treturn base64_audio_string\n",
    "\n",
    "#\n",
    "# Convert image to base64 string\n",
    "#\n",
    "def create_image_string(cell_image):\n",
    "\n",
    "\t# Define base64 image prefix\n",
    "\tbase64_image_prefix = \"data:image/png;base64,\"\n",
    "\n",
    "\t# Convert image to base64 string\n",
    "\tcell_image_buffer = BytesIO()\n",
    "\tcell_image.save(cell_image_buffer, format=\"PNG\")\n",
    "\tbase64_image_string = base64_image_prefix + base64.b64encode(cell_image_buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "\treturn base64_image_string\n",
    "\n",
    "#\n",
    "# Global adaptive thresholding\n",
    "#\n",
    "# Returns: binarized array\n",
    "#\n",
    "def global_adaptive_thresholding(image, height, width, depth):\n",
    "\n",
    "\t# Convert image to array\n",
    "\timage_array = np.asarray(image)\n",
    "\timage_array = image_array.reshape((height, width, depth))\n",
    "\n",
    "\t# Convert image to grayscale\n",
    "\tgrayscale_image = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t# Apply Otsu thresholding\n",
    "\totsu_threshold, binarized_array = cv2.threshold(grayscale_image, 127, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "\treturn binarized_array\n",
    "\n",
    "#\n",
    "# Return row bounding box from page text\n",
    "#\n",
    "def group_text_into_rows(page_text_pd, table_box):\n",
    "\n",
    "\t# Assemble text into rows\n",
    "\trows_dict = dict()\n",
    "\tfor index, text_data in page_text_pd.iterrows():\n",
    "\n",
    "\t\t# Get text top coordinate\n",
    "\t\ttext_top = text_data[\"top\"]\n",
    "\n",
    "\t\t# Only add elements that are within vertical table boundaries\n",
    "\t\tif text_top >= table_box[1] and text_top <= table_box[3]:\n",
    "\n",
    "\t\t\t# Check if row exists in dict\n",
    "\t\t\tif text_top in rows_dict:\n",
    "\n",
    "\t\t\t\t# Update row bounding box\n",
    "\t\t\t\ttext_row = rows_dict[text_top]\n",
    "\t\t\t\trows_dict[text_top] = {\n",
    "\t\t\t\t\t\"left\": min(text_row[\"left\"], text_data[\"left\"]),\n",
    "\t\t\t\t\t\"top\": min(text_row[\"top\"], text_data[\"top\"]),\n",
    "\t\t\t\t\t\"right\": max(text_row[\"right\"], text_data[\"right\"]),\n",
    "\t\t\t\t\t\"bottom\": max(text_row[\"bottom\"], text_data[\"bottom\"])\n",
    "\t\t\t\t}\n",
    "\t\t\telse:\n",
    "\n",
    "\t\t\t\t# Add new row\n",
    "\t\t\t\trows_dict[text_top] = {\n",
    "\t\t\t\t\t\"left\": text_data[\"left\"],\n",
    "\t\t\t\t\t\"top\": text_data[\"top\"],\n",
    "\t\t\t\t\t\"right\": text_data[\"right\"],\n",
    "\t\t\t\t\t\"bottom\": text_data[\"bottom\"]\n",
    "\t\t\t\t}\n",
    "\n",
    "\t# Assemble row boxes\n",
    "\trow_boxes = [row for _, row in rows_dict.items()]\n",
    "\n",
    "\t# Compute row height frequencies\n",
    "\trow_heights = {}\n",
    "\tfor row_box in row_boxes:\n",
    "\t\trow_height = row_box[\"bottom\"] - row_box[\"top\"]\n",
    "\t\trow_heights[row_height] = row_heights.get(row_height, 0) + 1\n",
    "\n",
    "\t# Compute baseline row height and acceptable range\n",
    "\tcomputed_row_height = max(row_heights, key=row_heights.get)\n",
    "\tcomputed_row_heights = list(range(int(computed_row_height * 0.5), int(computed_row_height * 2)))\n",
    "\n",
    "\t# Filter rows that are too short or tall\n",
    "\trow_boxes = [row_box for row_box in row_boxes if (row_box[\"bottom\"] - row_box[\"top\"]) in computed_row_heights]\n",
    "\n",
    "\t# Merge similar row boxes\n",
    "\trow_boxes = merge_similar_row_boxes(row_boxes, computed_row_height)\n",
    "\n",
    "\t# Sort boxes top to bottom\n",
    "\trow_boxes = sorted(row_boxes, key=lambda x: x[\"top\"])\n",
    "\n",
    "\t# Extract outer horizontal extents\n",
    "\ttypical_rows = [row_box for row_box in row_boxes if (row_box[\"bottom\"] - row_box[\"top\"]) == computed_row_height]\n",
    "\trow_left = table_box[0]\n",
    "\trow_right = table_box[2]\n",
    "\tfor row_box in typical_rows:\n",
    "\t\tif row_box[\"left\"] < row_left:\n",
    "\t\t\trow_left = row_box[\"left\"]\n",
    "\t\tif row_box[\"right\"] > row_right:\n",
    "\t\t\trow_right = row_box[\"right\"]\n",
    "\trow_left -= 1\n",
    "\trow_right += 5\n",
    "\n",
    "\t# Convert to tuples and filter out rows that aren't wide enough\n",
    "\tmin_width_ratio = 0.6\n",
    "\ttable_width = row_right - row_left\n",
    "\trow_boxes = [(row_box[\"left\"], row_box[\"top\"], row_box[\"right\"], row_box[\"bottom\"]) for row_box in row_boxes if ((row_box[\"right\"] - row_box[\"left\"]) / table_width) > min_width_ratio ]\n",
    "\n",
    "\t# Normalize rows to horizontal extents\n",
    "\trow_boxes = [(row_left, row_box[1], row_box[2], row_box[3]) for row_box in row_boxes]\n",
    "\n",
    "\treturn row_boxes, row_left, row_right\n",
    "\n",
    "#\n",
    "# Identify page text\n",
    "#\n",
    "def identify_page_text(image):\n",
    "\n",
    "\t# OCR page text\n",
    "\tpage_pd_ocr = pytesseract.image_to_data(image, output_type=\"data.frame\")\n",
    "\n",
    "\t# Drop any rows that identify blank text\n",
    "\tpage_pd_ocr.dropna(subset=[\"text\"], inplace=True)\n",
    "\n",
    "\t# Calculate other position values\n",
    "\tpage_pd_ocr[\"right\"] = page_pd_ocr[\"left\"] + page_pd_ocr[\"width\"]\n",
    "\tpage_pd_ocr[\"bottom\"] = page_pd_ocr[\"top\"] + page_pd_ocr[\"height\"]\n",
    "\n",
    "\t# Reset the dataframe index\n",
    "\tpage_pd_ocr.reset_index(inplace=True)\n",
    "\n",
    "\treturn page_pd_ocr\n",
    "\n",
    "#\n",
    "# Identify table columns\n",
    "#\n",
    "# - Returns column list, first column is leftmost item label column\n",
    "#\n",
    "def identify_table_columns(binarized_image, table_location, page_text_df, num_rows):\n",
    "\n",
    "\t# Instantiate model\n",
    "\ttable_model_structure = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-structure-recognition\")\n",
    "\n",
    "\t# Instantiate DETR model feature extractor\n",
    "\t# https://arxiv.org/abs/2005.12872\n",
    "\timage = binarized_image\n",
    "\tfeature_extractor = DetrFeatureExtractor()\n",
    "\tencoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "\n",
    "\t# Infer table location and structure\n",
    "\twith torch.no_grad():\n",
    "\t\tts_outputs = table_model_structure(**encoding)\n",
    "\n",
    "\ttarget_sizes = [image.size[::-1]]\n",
    "\tts_results = feature_extractor.post_process_object_detection(ts_outputs, threshold=0.7, target_sizes=target_sizes)[0]\n",
    "\n",
    "\t# Extract only columns\n",
    "\tmax_column_area = (table_location[2] - table_location[0]) * (table_location[3] - table_location[1]) * 0.8\n",
    "\tcolumn_boxes = [box for box in ts_results['boxes'] if is_column(box) and box_area(box)<max_column_area]\n",
    "\n",
    "\t# Sort columns left to right\n",
    "\tcolumn_boxes = sorted(column_boxes, key=lambda box: box[0])\n",
    "\n",
    "\t# Merge overlapping columns\n",
    "\toverlap_threshold = 0.2\n",
    "\toutput_columns = []\n",
    "\tfor column_box in column_boxes:\n",
    "\n",
    "\t\t# Add initial box\n",
    "\t\tif not output_columns:\n",
    "\t\t\toutput_columns.append(column_box)\n",
    "\t\t\tcontinue\n",
    "\t\telse:\n",
    "\n",
    "\t\t\t# Compute column area\n",
    "\t\t\tcolumn_area = (column_box[2] - column_box[0]) * (column_box[3] - column_box[1])\n",
    "\n",
    "\t\t\t# Compare candidate column with each preserved column\n",
    "\t\t\tcolumn_was_merged = False\n",
    "\t\t\tfor output_box in output_columns:\n",
    "\n",
    "\t\t\t\t# Calculate intersection over union (IoU)\n",
    "\t\t\t\toutput_area = (output_box[2] - output_box[0]) * (output_box[3] - output_box[1])\n",
    "\t\t\t\tintersection_area = (min(column_box[2], output_box[2]) - max(column_box[0], output_box[0])) * (output_box[3] - output_box[1])\n",
    "\t\t\t\tunion_area = column_area + output_area\n",
    "\t\t\t\tiou = intersection_area / union_area\n",
    "\n",
    "\t\t\t\t# Merge overlapping columns based on IoU threshold\n",
    "\t\t\t\tif iou > overlap_threshold:\n",
    "\t\t\t\t\tmerged_column = [min(output_box[0], column_box[0]), output_box[1], max(output_box[2], column_box[2]), output_box[3]]\n",
    "\t\t\t\t\toutput_columns.append(merged_column)\n",
    "\t\t\t\t\tcolumn_was_merged = True\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\t\t\n",
    "\t\t\t# Add column if not close\n",
    "\t\t\tif not column_was_merged:\n",
    "\t\t\t\toutput_columns.append(column_box)\n",
    "\tcolumn_boxes = output_columns\n",
    "\n",
    "\t# Discard rightmost columns that don't contain enough numbers\n",
    "\tcolumn_digits_threshold = 0.8 # The ratio of cells that must contain numbers\n",
    "\tvalid_column_boxes = [column_boxes[0]]\n",
    "\tfor i, col_box in enumerate(column_boxes[1:]):\n",
    "\n",
    "\t\t# Get text for any cells within the column boundaries\n",
    "\t\tcol_text_series = page_text_df[\n",
    "\t\t\t(page_text_df[\"left\"] >= int(col_box[0])) & \n",
    "\t\t\t(page_text_df[\"right\"] <= int(col_box[2])) & \n",
    "\t\t\t(page_text_df[\"top\"] >= int(table_location[1])) & \n",
    "\t\t\t(page_text_df[\"bottom\"] <= int(table_location[3]))\n",
    "\t\t\t][\"text\"]\n",
    "\n",
    "\t\t# Count the number of digits\n",
    "\t\tdigits_count = col_text_series.str.contains(\"[0-9]\").value_counts()\n",
    "\n",
    "\t\t# Reject columns that don't contain enough digits\n",
    "\t\tif True in digits_count:\n",
    "\n",
    "\t\t\t# Calculate percentage of cells with digits for this column\n",
    "\t\t\tnumber_cells_ratio = digits_count.loc[True] / num_rows\n",
    "\n",
    "\t\t\t# Only keep columns that meet the threshold amount\n",
    "\t\t\tif number_cells_ratio >= column_digits_threshold:\n",
    "\t\t\t\tvalid_column_boxes.append(col_box)\n",
    "\tcolumn_boxes = valid_column_boxes\n",
    "\n",
    "\t# Clip columns to table boundaries\n",
    "\tcolumn_boxes = [(max(column_box[0], table_location[0]), table_location[1], min(column_box[2], table_location[2]), table_location[3]) for column_box in column_boxes]\n",
    "\n",
    "\t# Extend first column to left edge\n",
    "\tcolumn_boxes[0] = (min(column_boxes[0][0], table_location[0]), column_boxes[0][1], column_boxes[0][2], column_boxes[0][3])\n",
    "\n",
    "\treturn column_boxes\n",
    "\n",
    "#\n",
    "# Check if bounding box is a column\n",
    "#\n",
    "def is_column(box):\n",
    "  if (box[2]-box[0]) < (box[3]-box[1]):\n",
    "    return True\n",
    "  return False\n",
    "\n",
    "#\n",
    "# Merge similar rows\n",
    "#\n",
    "def merge_similar_row_boxes(row_boxes, row_height):\n",
    "\n",
    "\toutput_boxes = []\n",
    "\n",
    "\t# Process all row boxes\n",
    "\tproximity_tolerance = int(row_height * 0.5)\n",
    "\tfor row_box in row_boxes:\n",
    "\n",
    "\t\t# Add initial box\n",
    "\t\tif not output_boxes:\n",
    "\t\t\toutput_boxes.append(row_box)\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\telse:\n",
    "\n",
    "\t\t\t# Get current row middle\n",
    "\t\t\tcurrent_middle = row_box[\"top\"] + (row_box[\"bottom\"] - row_box[\"top\"])\n",
    "\n",
    "\t\t\t# Check for approximate top value key\n",
    "\t\t\tmatched_row = False\n",
    "\t\t\tfor output_idx, output_row in enumerate(output_boxes):\n",
    "\t\t\t\t\n",
    "\t\t\t\t# Calculate output box middle\n",
    "\t\t\t\toutput_middle = output_row[\"top\"] + (output_row[\"bottom\"] - output_row[\"top\"])\n",
    "\n",
    "\t\t\t\t# Merge bounding boxes if middles are close\n",
    "\t\t\t\tmiddle_distance = abs(output_middle - current_middle)\n",
    "\t\t\t\tif middle_distance <= proximity_tolerance:\n",
    "\t\t\t\t\tmatched_row = True\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\t# Merge close matches\n",
    "\t\t\tif matched_row:\n",
    "\t\t\t\toutput_boxes[output_idx] = {\n",
    "\t\t\t\t\t\"left\": min(output_row[\"left\"], row_box[\"left\"]),\n",
    "\t\t\t\t\t\"top\": min(output_row[\"top\"], row_box[\"top\"]),\n",
    "\t\t\t\t\t\"right\": max(output_row[\"right\"], row_box[\"right\"]),\n",
    "\t\t\t\t\t\"bottom\": max(output_row[\"bottom\"], row_box[\"bottom\"]),\n",
    "\t\t\t\t}\n",
    "\t\t\telse:\n",
    "\t\t\t\t# No approximate match, so add row to output as a new unique row\n",
    "\t\t\t\toutput_boxes.append(row_box)\n",
    "\n",
    "\treturn output_boxes\n",
    "\n",
    "#\n",
    "# Parse row data\n",
    "#\n",
    "def parse_rows(page_image, row_boxes, column_boxes, page_text_df):\n",
    "\n",
    "\t# Define boxes\n",
    "\tlabel_column_box = column_boxes[0]\n",
    "\tdata_column_box = column_boxes[1]\n",
    "\t\n",
    "\t# Process each row\n",
    "\trow_elements = []\n",
    "\tfor row_box in row_boxes:\n",
    "\n",
    "\t\t# Define cell boxes\n",
    "\t\tlabel_cell_box = (int(label_column_box[0]), int(row_box[1]), int(label_column_box[2]), int(row_box[3]))\n",
    "\t\tdata_cell_box = (int(data_column_box[0]), int(row_box[1]), int(data_column_box[2]), int(row_box[3]))\n",
    "\n",
    "\t\t# Extract label text\n",
    "\t\tlabel_text_series = page_text_df[\n",
    "\t\t\t(page_text_df[\"left\"] >= label_cell_box[0]) & \n",
    "\t\t\t(page_text_df[\"right\"] <= label_cell_box[2]) & \n",
    "\t\t\t(page_text_df[\"top\"] >= label_cell_box[1]) & \n",
    "\t\t\t(page_text_df[\"bottom\"] <= label_cell_box[3])\n",
    "\t\t\t]\n",
    "\t\tlabel_text = \" \".join(label_text_series[\"text\"]).strip()\n",
    "\n",
    "\t\t# Extract data text\n",
    "\t\tdata_text_series = page_text_df[\n",
    "\t\t\t(page_text_df[\"left\"] >= data_cell_box[0]) & \n",
    "\t\t\t(page_text_df[\"right\"] <= data_cell_box[2]) & \n",
    "\t\t\t(page_text_df[\"top\"] >= data_cell_box[1]) & \n",
    "\t\t\t(page_text_df[\"bottom\"] <= data_cell_box[3])\n",
    "\t\t\t]\n",
    "\t\t\n",
    "\t\t# DEBUG\n",
    "\t\tif label_text == \"Total assets\":\n",
    "\t\t\tprint(data_text_series)\n",
    "\n",
    "\t\tdata_text = \" \".join(data_text_series[\"text\"]).strip()\n",
    "\n",
    "\t\t# Strip non-value characters from all elements\n",
    "\t\tdata_text = re.sub(r\"[^0-9(). ]+\", \"\", data_text)\n",
    "\n",
    "\t\t# DEBUG\n",
    "\t\tif label_text == \"Total assets\":\n",
    "\t\t\tprint(f\"Total assets: {data_text}\")\n",
    "\n",
    "\t\t# Strip mismatched parentheses\n",
    "\t\tif \"(\" in data_text and \")\" not in data_text:\n",
    "\t\t\tdata_text = data_text.replace(\"(\", \"\")\n",
    "\t\telif \"(\" not in data_text and \")\" in data_text:\n",
    "\t\t\tdata_text = data_text.replace(\")\", \"\")\n",
    "\n",
    "\t\t# Extract data cell image\n",
    "\t\tdata_image = page_image.crop(data_cell_box)\n",
    "\n",
    "\t\t# Assemble row\n",
    "\t\trow_element = { \"label\": label_text, \"value\": data_text, \"cell_image\": data_image }\n",
    "\t\trow_elements.append(row_element)\n",
    "\n",
    "\t# Assemble rows bundle\n",
    "\tnum_rows = len(row_elements)\n",
    "\trows_bundle = { \"elements\": row_elements, \"num_extracted_values\": num_rows }\n",
    "\n",
    "\treturn rows_bundle\n",
    "\n",
    "#\n",
    "# Extract data from image\n",
    "#\n",
    "def process_image(page_image):\n",
    "\n",
    "  # Parse image dimensions\n",
    "\tpage_width = page_image.width\n",
    "\tpage_height = page_image.height\n",
    "\tpage_depth = 3\n",
    "\tprint(f\"Image dimensions: {page_width} x {page_height} x {page_depth}\")\n",
    "\n",
    "\t# Binarize image\n",
    "\tbinarized_array = global_adaptive_thresholding(page_image, page_height, page_width, page_depth)\n",
    "\n",
    "\t# Display image\n",
    "\tbinarized_image = Image.fromarray(binarized_array).convert(\"RGB\")\n",
    "\n",
    "\t# Segment table\n",
    "\ttable_location = segment_table(binarized_image)\n",
    "\tif table_location == None:\n",
    "\t\treturn None\n",
    "\n",
    "\t# Identify entire page text\n",
    "\tpage_text_df = identify_page_text(page_image)\n",
    "\n",
    "\t# DEBUG\n",
    "\tdisplay_line = 104\n",
    "\tdisplay(page_text_df[display_line:display_line + 10])\n",
    "\n",
    "\t# Group page text into rows\n",
    "\trow_boxes, row_left, row_right = group_text_into_rows(page_text_df, table_location)\n",
    "\tprint(f\"Number of rows: {len(row_boxes)}\")\n",
    "\n",
    "\t# Adjust horizontal table boundaries based on detected row data\n",
    "\tif row_left < table_location[0]:\n",
    "\t\ttable_location[0] = row_left\n",
    "\tif row_right > table_location[2]:\n",
    "\t\ttable_location[2] = row_right\n",
    "\n",
    "\t# Identify table columns\n",
    "\tcolumn_boxes = identify_table_columns(binarized_image, table_location, page_text_df, len(row_boxes))\n",
    "\n",
    "\t# DEBUG: Plot all rows on a single image\n",
    "\t# relevant_columns = [column_boxes[0], column_boxes[1]]\n",
    "\t# draw_page_boxes(page_image, table_location, row_boxes, relevant_columns)\n",
    "\n",
    "\t# Parse the rows\n",
    "\trow_data = parse_rows(page_image, row_boxes, column_boxes, page_text_df)\n",
    "\n",
    "\t# Assemble validation data\n",
    "\tvalidation_data = []\n",
    "\tfor element in row_data[\"elements\"]:\n",
    "\n",
    "\t\t# Convert cell to base64 image\n",
    "\t\tcell_image_string = create_image_string(element[\"cell_image\"])\n",
    "\n",
    "\t\t# Convert cell  to base64 audio\n",
    "\t\tcell_audio_string = create_audio_string(element[\"value\"])\n",
    "\n",
    "\t\t# DEBUG\n",
    "\t\tif element[\"label\"] == \"Total assets\":\n",
    "\t\t\tprint(f'{element[\"label\"]}: {element[\"value\"]}')\n",
    "\n",
    "\t\t# Assemble data element\n",
    "\t\tvalidation_data.append({\"label\": element[\"label\"], \"extracted_value\": element[\"value\"], \"cell_image\": cell_image_string, \"audio\": cell_audio_string })\n",
    "\n",
    "\t# Return validation data\n",
    "\treturn validation_data\n",
    "\n",
    "#\n",
    "# Segment table\n",
    "#\n",
    "def segment_table(binarized_image):\n",
    "\n",
    "\t# Instantiate model\n",
    "\ttable_model_location = TableTransformerForObjectDetection.from_pretrained(\"microsoft/table-transformer-detection\")\n",
    "\t\n",
    "\t# Instantiate DETR model feature extractor\n",
    "\t# https://arxiv.org/abs/2005.12872\n",
    "\timage = binarized_image\n",
    "\tfeature_extractor = DetrFeatureExtractor()\n",
    "\tencoding = feature_extractor(image, return_tensors=\"pt\")\n",
    "\n",
    "\t# Infer table location and structure\n",
    "\twith torch.no_grad():\n",
    "\t\ttl_outputs = table_model_location(**encoding)\n",
    "\n",
    "\twidth, height = image.size\n",
    "\tlocation_results = feature_extractor.post_process_object_detection(tl_outputs, threshold=0.2, target_sizes=[(height, width)])[0]\n",
    "\n",
    "\t# No table detected\n",
    "\tnum_table_boxes = len(location_results['boxes'])\n",
    "\tif num_table_boxes == 0:\n",
    "\t\treturn None\n",
    "\n",
    "\t# Extract table location\n",
    "\tpadding = 5\n",
    "\ttable_location = location_results[\"boxes\"][0].tolist()\n",
    "\ttable_location = [table_location[0] - padding, table_location[1], table_location[2] + padding, table_location[3]]\n",
    "\n",
    "\treturn table_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\UoL\\Final Project\\Prototype\\.venv\\lib\\site-packages\\transformers\\models\\detr\\feature_extraction_detr.py:28: FutureWarning: The class DetrFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use DetrImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions: 2125 x 2750 x 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>level</th>\n",
       "      <th>page_num</th>\n",
       "      <th>block_num</th>\n",
       "      <th>par_num</th>\n",
       "      <th>line_num</th>\n",
       "      <th>word_num</th>\n",
       "      <th>left</th>\n",
       "      <th>top</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>conf</th>\n",
       "      <th>text</th>\n",
       "      <th>right</th>\n",
       "      <th>bottom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>189</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>944</td>\n",
       "      <td>859</td>\n",
       "      <td>57</td>\n",
       "      <td>19</td>\n",
       "      <td>90.743698</td>\n",
       "      <td>Note</td>\n",
       "      <td>1001</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>190</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1014</td>\n",
       "      <td>858</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>90.743698</td>\n",
       "      <td>2Q</td>\n",
       "      <td>1048</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>191</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1251</td>\n",
       "      <td>858</td>\n",
       "      <td>46</td>\n",
       "      <td>21</td>\n",
       "      <td>96.776451</td>\n",
       "      <td>110</td>\n",
       "      <td>1297</td>\n",
       "      <td>879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>192</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1533</td>\n",
       "      <td>859</td>\n",
       "      <td>44</td>\n",
       "      <td>19</td>\n",
       "      <td>96.685204</td>\n",
       "      <td>111</td>\n",
       "      <td>1577</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>193</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1793</td>\n",
       "      <td>859</td>\n",
       "      <td>45</td>\n",
       "      <td>19</td>\n",
       "      <td>96.675613</td>\n",
       "      <td>115</td>\n",
       "      <td>1838</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>196</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>292</td>\n",
       "      <td>901</td>\n",
       "      <td>94</td>\n",
       "      <td>25</td>\n",
       "      <td>96.297195</td>\n",
       "      <td>Prepaid</td>\n",
       "      <td>386</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>197</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>398</td>\n",
       "      <td>906</td>\n",
       "      <td>120</td>\n",
       "      <td>20</td>\n",
       "      <td>96.297195</td>\n",
       "      <td>expenses</td>\n",
       "      <td>518</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>198</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>529</td>\n",
       "      <td>901</td>\n",
       "      <td>45</td>\n",
       "      <td>20</td>\n",
       "      <td>96.283501</td>\n",
       "      <td>and</td>\n",
       "      <td>574</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>199</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>587</td>\n",
       "      <td>901</td>\n",
       "      <td>68</td>\n",
       "      <td>20</td>\n",
       "      <td>96.106148</td>\n",
       "      <td>other</td>\n",
       "      <td>655</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>665</td>\n",
       "      <td>902</td>\n",
       "      <td>93</td>\n",
       "      <td>19</td>\n",
       "      <td>96.106148</td>\n",
       "      <td>current</td>\n",
       "      <td>758</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index  level  page_num  block_num  par_num  line_num  word_num  left  \\\n",
       "104    189      5         1         21        9         1         6   944   \n",
       "105    190      5         1         21        9         1         7  1014   \n",
       "106    191      5         1         21        9         1         8  1251   \n",
       "107    192      5         1         21        9         1         9  1533   \n",
       "108    193      5         1         21        9         1        10  1793   \n",
       "109    196      5         1         21       10         1         1   292   \n",
       "110    197      5         1         21       10         1         2   398   \n",
       "111    198      5         1         21       10         1         3   529   \n",
       "112    199      5         1         21       10         1         4   587   \n",
       "113    200      5         1         21       10         1         5   665   \n",
       "\n",
       "     top  width  height       conf      text  right  bottom  \n",
       "104  859     57      19  90.743698      Note   1001     878  \n",
       "105  858     34      25  90.743698        2Q   1048     883  \n",
       "106  858     46      21  96.776451       110   1297     879  \n",
       "107  859     44      19  96.685204       111   1577     878  \n",
       "108  859     45      19  96.675613       115   1838     878  \n",
       "109  901     94      25  96.297195   Prepaid    386     926  \n",
       "110  906    120      20  96.297195  expenses    518     926  \n",
       "111  901     45      20  96.283501       and    574     921  \n",
       "112  901     68      20  96.106148     other    655     921  \n",
       "113  902     93      19  96.106148   current    758     921  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\UoL\\Final Project\\Prototype\\.venv\\lib\\site-packages\\transformers\\models\\detr\\feature_extraction_detr.py:28: FutureWarning: The class DetrFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use DetrImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index  level  page_num  block_num  par_num  line_num  word_num  left  \\\n",
      "174    269      5         1         21       10         9         3  1122   \n",
      "175    270      5         1         21       10         9         4  1198   \n",
      "\n",
      "      top  width  height       conf    text  right  bottom  \n",
      "174  1249     15      25  92.847580       $   1137    1274  \n",
      "175  1249     99      25  96.723335  27,759   1297    1274  \n",
      "Total assets:  27759\n",
      "Total assets:  27759\n"
     ]
    }
   ],
   "source": [
    "import fitz # This is actually PyMuPDF\n",
    "\n",
    "# Specify financial statement filename\n",
    "# statement_filename, page_index = \"../statements/407 International - March 31 2021.pdf\", 1\n",
    "statement_filename, page_index = \"../statements/Air Canada - December 31 2019.pdf\", 6\n",
    "# statement_filename, page_index = \"../statements/BCE - Financial Report - 2020-2022.pdf\", 82\n",
    "# statement_filename, page_index = \"../statements/Better Life Pharma Inc - Jan 31 Oct 31 2022.pdf\", 2\n",
    "# statement_filename, page_index = \"../statements/NextGen Food Robotics Corp - 2022-04-30 - 2023-01-31..pdf\", 2\n",
    "# statement_filename, page_index = \"../statements/Rogers - Q1-2020.pdf\", 3\n",
    "# statement_filename, page_index = \"../statements/Starbucks - Annual Report - 2020.pdf\", 53\n",
    "\n",
    "# Convert PDF page to image\n",
    "statement_pages = []\n",
    "statement_doc = fitz.open(statement_filename)\n",
    "statement_page = statement_doc[page_index].get_pixmap(dpi=250)\n",
    "\n",
    "# Convert PDF page to image\n",
    "page_pixmap = statement_page #s[page_index]\n",
    "page_image = Image.frombytes(\"RGB\", [page_pixmap.width, page_pixmap.height], page_pixmap.samples)\n",
    "\n",
    "# Parse image dimensions\n",
    "page_width = page_image.width\n",
    "page_height = page_image.height\n",
    "page_depth = 3\n",
    "\n",
    "# Binarize image\n",
    "binarized_array = global_adaptive_thresholding(page_image, page_height, page_width, page_depth)\n",
    "\n",
    "# Display image\n",
    "binarized_image = Image.fromarray(binarized_array).convert(\"RGB\")\n",
    "\n",
    "# Segment table\n",
    "table_location = segment_table(binarized_image)\n",
    "\n",
    "# Display image\n",
    "# display_ratio = page_image.width / 500\n",
    "# display_size = (int(page_image.width / display_ratio), int(page_image.height / display_ratio))\n",
    "# display_image = page_image.resize(display_size)\n",
    "# display(display_image)\n",
    "\n",
    "# Process page image\n",
    "validation_data = process_image(page_image)\n",
    "#display(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
